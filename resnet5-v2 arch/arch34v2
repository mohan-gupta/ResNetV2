digraph {
	graph [size="111.45,111.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2352538901456 [label="
 (1000)" fillcolor=darkolivegreen1]
	2352532578208 [label=AddBackward0]
	2352532578016 -> 2352532578208
	2352532578016 [label=SqueezeBackward3]
	2352532578112 -> 2352532578016
	2352532578112 [label=MmBackward0]
	2352538935456 -> 2352532578112
	2352538935456 [label=UnsqueezeBackward0]
	2352538935600 -> 2352538935456
	2352538935600 [label=ViewBackward0]
	2352538935696 -> 2352538935600
	2352538935696 [label=MeanBackward1]
	2352538935792 -> 2352538935696
	2352538935792 [label=ReluBackward0]
	2352538935888 -> 2352538935792
	2352538935888 [label=NativeBatchNormBackward0]
	2352538935984 -> 2352538935888
	2352538935984 [label=AddBackward0]
	2352538936176 -> 2352538935984
	2352538936176 [label=ConvolutionBackward0]
	2352538936320 -> 2352538936176
	2352538936320 [label=ReluBackward0]
	2352538936464 -> 2352538936320
	2352538936464 [label=NativeBatchNormBackward0]
	2352538936560 -> 2352538936464
	2352538936560 [label=ConvolutionBackward0]
	2352538936752 -> 2352538936560
	2352538936752 [label=ReluBackward0]
	2352538936896 -> 2352538936752
	2352538936896 [label=NativeBatchNormBackward0]
	2352538936128 -> 2352538936896
	2352538936128 [label=AddBackward0]
	2352538937136 -> 2352538936128
	2352538937136 [label=ConvolutionBackward0]
	2352538937280 -> 2352538937136
	2352538937280 [label=ReluBackward0]
	2352538937424 -> 2352538937280
	2352538937424 [label=NativeBatchNormBackward0]
	2352538937520 -> 2352538937424
	2352538937520 [label=ConvolutionBackward0]
	2352538937712 -> 2352538937520
	2352538937712 [label=ReluBackward0]
	2352538937856 -> 2352538937712
	2352538937856 [label=NativeBatchNormBackward0]
	2352538937088 -> 2352538937856
	2352538937088 [label=AddBackward0]
	2352538938096 -> 2352538937088
	2352538938096 [label=ConvolutionBackward0]
	2352538938240 -> 2352538938096
	2352538938240 [label=ReluBackward0]
	2352538938384 -> 2352538938240
	2352538938384 [label=NativeBatchNormBackward0]
	2352538938528 -> 2352538938384
	2352538938528 [label=ConvolutionBackward0]
	2352538938720 -> 2352538938528
	2352538938720 [label=ReluBackward0]
	2352538938864 -> 2352538938720
	2352538938864 [label=NativeBatchNormBackward0]
	2352538939008 -> 2352538938864
	2352538939008 [label=AddBackward0]
	2352538939200 -> 2352538939008
	2352538939200 [label=ConvolutionBackward0]
	2352538939344 -> 2352538939200
	2352538939344 [label=ReluBackward0]
	2352538947744 -> 2352538939344
	2352538947744 [label=NativeBatchNormBackward0]
	2352538947888 -> 2352538947744
	2352538947888 [label=ConvolutionBackward0]
	2352538948080 -> 2352538947888
	2352538948080 [label=ReluBackward0]
	2352538948224 -> 2352538948080
	2352538948224 [label=NativeBatchNormBackward0]
	2352538939152 -> 2352538948224
	2352538939152 [label=AddBackward0]
	2352538948512 -> 2352538939152
	2352538948512 [label=ConvolutionBackward0]
	2352538948656 -> 2352538948512
	2352538948656 [label=ReluBackward0]
	2352538948800 -> 2352538948656
	2352538948800 [label=NativeBatchNormBackward0]
	2352538948944 -> 2352538948800
	2352538948944 [label=ConvolutionBackward0]
	2352538949136 -> 2352538948944
	2352538949136 [label=ReluBackward0]
	2352538949280 -> 2352538949136
	2352538949280 [label=NativeBatchNormBackward0]
	2352538948464 -> 2352538949280
	2352538948464 [label=AddBackward0]
	2352538949568 -> 2352538948464
	2352538949568 [label=ConvolutionBackward0]
	2352538949712 -> 2352538949568
	2352538949712 [label=ReluBackward0]
	2352538949856 -> 2352538949712
	2352538949856 [label=NativeBatchNormBackward0]
	2352538950000 -> 2352538949856
	2352538950000 [label=ConvolutionBackward0]
	2352538950192 -> 2352538950000
	2352538950192 [label=ReluBackward0]
	2352538950336 -> 2352538950192
	2352538950336 [label=NativeBatchNormBackward0]
	2352538949520 -> 2352538950336
	2352538949520 [label=AddBackward0]
	2352538950624 -> 2352538949520
	2352538950624 [label=ConvolutionBackward0]
	2352538950768 -> 2352538950624
	2352538950768 [label=ReluBackward0]
	2352538950912 -> 2352538950768
	2352538950912 [label=NativeBatchNormBackward0]
	2352538951056 -> 2352538950912
	2352538951056 [label=ConvolutionBackward0]
	2352538951248 -> 2352538951056
	2352538951248 [label=ReluBackward0]
	2352538951392 -> 2352538951248
	2352538951392 [label=NativeBatchNormBackward0]
	2352538950576 -> 2352538951392
	2352538950576 [label=AddBackward0]
	2352538951632 -> 2352538950576
	2352538951632 [label=ConvolutionBackward0]
	2352538964176 -> 2352538951632
	2352538964176 [label=ReluBackward0]
	2352538964320 -> 2352538964176
	2352538964320 [label=NativeBatchNormBackward0]
	2352538964464 -> 2352538964320
	2352538964464 [label=ConvolutionBackward0]
	2352538964656 -> 2352538964464
	2352538964656 [label=ReluBackward0]
	2352538964800 -> 2352538964656
	2352538964800 [label=NativeBatchNormBackward0]
	2352538951584 -> 2352538964800
	2352538951584 [label=AddBackward0]
	2352538965088 -> 2352538951584
	2352538965088 [label=ConvolutionBackward0]
	2352538965232 -> 2352538965088
	2352538965232 [label=ReluBackward0]
	2352538965376 -> 2352538965232
	2352538965376 [label=NativeBatchNormBackward0]
	2352538965520 -> 2352538965376
	2352538965520 [label=ConvolutionBackward0]
	2352538965712 -> 2352538965520
	2352538965712 [label=ReluBackward0]
	2352538965856 -> 2352538965712
	2352538965856 [label=NativeBatchNormBackward0]
	2352538966000 -> 2352538965856
	2352538966000 [label=AddBackward0]
	2352538966192 -> 2352538966000
	2352538966192 [label=ConvolutionBackward0]
	2352538966336 -> 2352538966192
	2352538966336 [label=ReluBackward0]
	2352538966480 -> 2352538966336
	2352538966480 [label=NativeBatchNormBackward0]
	2352538966624 -> 2352538966480
	2352538966624 [label=ConvolutionBackward0]
	2352538966816 -> 2352538966624
	2352538966816 [label=ReluBackward0]
	2352538966960 -> 2352538966816
	2352538966960 [label=NativeBatchNormBackward0]
	2352538966144 -> 2352538966960
	2352538966144 [label=AddBackward0]
	2352538967248 -> 2352538966144
	2352538967248 [label=ConvolutionBackward0]
	2352538967392 -> 2352538967248
	2352538967392 [label=ReluBackward0]
	2352538967536 -> 2352538967392
	2352538967536 [label=NativeBatchNormBackward0]
	2352538967680 -> 2352538967536
	2352538967680 [label=ConvolutionBackward0]
	2352538967872 -> 2352538967680
	2352538967872 [label=ReluBackward0]
	2352538968016 -> 2352538967872
	2352538968016 [label=NativeBatchNormBackward0]
	2352538967200 -> 2352538968016
	2352538967200 [label=AddBackward0]
	2352616964400 -> 2352538967200
	2352616964400 [label=ConvolutionBackward0]
	2352616964544 -> 2352616964400
	2352616964544 [label=ReluBackward0]
	2352616964688 -> 2352616964544
	2352616964688 [label=NativeBatchNormBackward0]
	2352616964832 -> 2352616964688
	2352616964832 [label=ConvolutionBackward0]
	2352616965024 -> 2352616964832
	2352616965024 [label=ReluBackward0]
	2352616965168 -> 2352616965024
	2352616965168 [label=NativeBatchNormBackward0]
	2352616964352 -> 2352616965168
	2352616964352 [label=AddBackward0]
	2352616965456 -> 2352616964352
	2352616965456 [label=ConvolutionBackward0]
	2352616965600 -> 2352616965456
	2352616965600 [label=ReluBackward0]
	2352616965744 -> 2352616965600
	2352616965744 [label=NativeBatchNormBackward0]
	2352616965888 -> 2352616965744
	2352616965888 [label=ConvolutionBackward0]
	2352616966080 -> 2352616965888
	2352616966080 [label=ReluBackward0]
	2352616966224 -> 2352616966080
	2352616966224 [label=NativeBatchNormBackward0]
	2352616966368 -> 2352616966224
	2352616966368 [label=AddBackward0]
	2352616966560 -> 2352616966368
	2352616966560 [label=ConvolutionBackward0]
	2352616966704 -> 2352616966560
	2352616966704 [label=ReluBackward0]
	2352616966848 -> 2352616966704
	2352616966848 [label=NativeBatchNormBackward0]
	2352616966992 -> 2352616966848
	2352616966992 [label=ConvolutionBackward0]
	2352616967184 -> 2352616966992
	2352616967184 [label=ReluBackward0]
	2352616967328 -> 2352616967184
	2352616967328 [label=NativeBatchNormBackward0]
	2352616966512 -> 2352616967328
	2352616966512 [label=AddBackward0]
	2352616967616 -> 2352616966512
	2352616967616 [label=ConvolutionBackward0]
	2352616967760 -> 2352616967616
	2352616967760 [label=ReluBackward0]
	2352616967904 -> 2352616967760
	2352616967904 [label=NativeBatchNormBackward0]
	2352616968048 -> 2352616967904
	2352616968048 [label=ConvolutionBackward0]
	2352616968144 -> 2352616968048
	2352616968144 [label=ReluBackward0]
	2352616980736 -> 2352616968144
	2352616980736 [label=NativeBatchNormBackward0]
	2352616967568 -> 2352616980736
	2352616967568 [label=AddBackward0]
	2352616981024 -> 2352616967568
	2352616981024 [label=ConvolutionBackward0]
	2352616981168 -> 2352616981024
	2352616981168 [label=ReluBackward0]
	2352616981312 -> 2352616981168
	2352616981312 [label=NativeBatchNormBackward0]
	2352616981456 -> 2352616981312
	2352616981456 [label=ConvolutionBackward0]
	2352616981648 -> 2352616981456
	2352616981648 [label=ReluBackward0]
	2352616981792 -> 2352616981648
	2352616981792 [label=NativeBatchNormBackward0]
	2352616981936 -> 2352616981792
	2352616981936 [label=MaxPool2DWithIndicesBackward0]
	2352616982128 -> 2352616981936
	2352616982128 [label=ConvolutionBackward0]
	2352616982272 -> 2352616982128
	2352532398464 [label="conv_1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2352532398464 -> 2352616982272
	2352616982272 [label=AccumulateGrad]
	2352616982224 -> 2352616982128
	2352532398544 [label="conv_1.bias
 (64)" fillcolor=lightblue]
	2352532398544 -> 2352616982224
	2352616982224 [label=AccumulateGrad]
	2352616981888 -> 2352616981792
	2352532398624 [label="layer1.0.block.bn1.weight
 (64)" fillcolor=lightblue]
	2352532398624 -> 2352616981888
	2352616981888 [label=AccumulateGrad]
	2352616981840 -> 2352616981792
	2352532398704 [label="layer1.0.block.bn1.bias
 (64)" fillcolor=lightblue]
	2352532398704 -> 2352616981840
	2352616981840 [label=AccumulateGrad]
	2352616981600 -> 2352616981456
	2352532399104 [label="layer1.0.block.conv_x_1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2352532399104 -> 2352616981600
	2352616981600 [label=AccumulateGrad]
	2352616981408 -> 2352616981312
	2352532399184 [label="layer1.0.block.bn2.weight
 (64)" fillcolor=lightblue]
	2352532399184 -> 2352616981408
	2352616981408 [label=AccumulateGrad]
	2352616981360 -> 2352616981312
	2352532399264 [label="layer1.0.block.bn2.bias
 (64)" fillcolor=lightblue]
	2352532399264 -> 2352616981360
	2352616981360 [label=AccumulateGrad]
	2352616981120 -> 2352616981024
	2352532399664 [label="layer1.0.block.conv_x_2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2352532399664 -> 2352616981120
	2352616981120 [label=AccumulateGrad]
	2352616980976 -> 2352616967568
	2352616980976 [label=ConvolutionBackward0]
	2352616981504 -> 2352616980976
	2352616981504 [label=ReluBackward0]
	2352616981984 -> 2352616981504
	2352616981984 [label=NativeBatchNormBackward0]
	2352616981936 -> 2352616981984
	2352616982176 -> 2352616981984
	2352532399744 [label="layer1.0.bn_proj.weight
 (64)" fillcolor=lightblue]
	2352532399744 -> 2352616982176
	2352616982176 [label=AccumulateGrad]
	2352616981744 -> 2352616981984
	2352532399824 [label="layer1.0.bn_proj.bias
 (64)" fillcolor=lightblue]
	2352532399824 -> 2352616981744
	2352616981744 [label=AccumulateGrad]
	2352616981552 -> 2352616980976
	2352532400224 [label="layer1.0.projection.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2352532400224 -> 2352616981552
	2352616981552 [label=AccumulateGrad]
	2352616980880 -> 2352616980736
	2352532400304 [label="layer1.1.block.bn1.weight
 (64)" fillcolor=lightblue]
	2352532400304 -> 2352616980880
	2352616980880 [label=AccumulateGrad]
	2352616980832 -> 2352616980736
	2352532400384 [label="layer1.1.block.bn1.bias
 (64)" fillcolor=lightblue]
	2352532400384 -> 2352616980832
	2352616980832 [label=AccumulateGrad]
	2352616980592 -> 2352616968048
	2352532400784 [label="layer1.1.block.conv_x_1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2352532400784 -> 2352616980592
	2352616980592 [label=AccumulateGrad]
	2352616968000 -> 2352616967904
	2352532400864 [label="layer1.1.block.bn2.weight
 (64)" fillcolor=lightblue]
	2352532400864 -> 2352616968000
	2352616968000 [label=AccumulateGrad]
	2352616967952 -> 2352616967904
	2352532400944 [label="layer1.1.block.bn2.bias
 (64)" fillcolor=lightblue]
	2352532400944 -> 2352616967952
	2352616967952 [label=AccumulateGrad]
	2352616967712 -> 2352616967616
	2352532401344 [label="layer1.1.block.conv_x_2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2352532401344 -> 2352616967712
	2352616967712 [label=AccumulateGrad]
	2352616967568 -> 2352616966512
	2352616967472 -> 2352616967328
	2352532401424 [label="layer1.2.block.bn1.weight
 (64)" fillcolor=lightblue]
	2352532401424 -> 2352616967472
	2352616967472 [label=AccumulateGrad]
	2352616967424 -> 2352616967328
	2352532401504 [label="layer1.2.block.bn1.bias
 (64)" fillcolor=lightblue]
	2352532401504 -> 2352616967424
	2352616967424 [label=AccumulateGrad]
	2352616967136 -> 2352616966992
	2352532401904 [label="layer1.2.block.conv_x_1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2352532401904 -> 2352616967136
	2352616967136 [label=AccumulateGrad]
	2352616966944 -> 2352616966848
	2352532401984 [label="layer1.2.block.bn2.weight
 (64)" fillcolor=lightblue]
	2352532401984 -> 2352616966944
	2352616966944 [label=AccumulateGrad]
	2352616966896 -> 2352616966848
	2352532402064 [label="layer1.2.block.bn2.bias
 (64)" fillcolor=lightblue]
	2352532402064 -> 2352616966896
	2352616966896 [label=AccumulateGrad]
	2352616966656 -> 2352616966560
	2352532459904 [label="layer1.2.block.conv_x_2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2352532459904 -> 2352616966656
	2352616966656 [label=AccumulateGrad]
	2352616966512 -> 2352616966368
	2352616966320 -> 2352616966224
	2352532459984 [label="layer2.0.block.bn1.weight
 (64)" fillcolor=lightblue]
	2352532459984 -> 2352616966320
	2352616966320 [label=AccumulateGrad]
	2352616966272 -> 2352616966224
	2352532460064 [label="layer2.0.block.bn1.bias
 (64)" fillcolor=lightblue]
	2352532460064 -> 2352616966272
	2352616966272 [label=AccumulateGrad]
	2352616966032 -> 2352616965888
	2352532460464 [label="layer2.0.block.conv_x_1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2352532460464 -> 2352616966032
	2352616966032 [label=AccumulateGrad]
	2352616965840 -> 2352616965744
	2352532460544 [label="layer2.0.block.bn2.weight
 (128)" fillcolor=lightblue]
	2352532460544 -> 2352616965840
	2352616965840 [label=AccumulateGrad]
	2352616965792 -> 2352616965744
	2352532460624 [label="layer2.0.block.bn2.bias
 (128)" fillcolor=lightblue]
	2352532460624 -> 2352616965792
	2352616965792 [label=AccumulateGrad]
	2352616965552 -> 2352616965456
	2352532461024 [label="layer2.0.block.conv_x_2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2352532461024 -> 2352616965552
	2352616965552 [label=AccumulateGrad]
	2352616965408 -> 2352616964352
	2352616965408 [label=ConvolutionBackward0]
	2352616965936 -> 2352616965408
	2352616965936 [label=ReluBackward0]
	2352616966416 -> 2352616965936
	2352616966416 [label=NativeBatchNormBackward0]
	2352616966368 -> 2352616966416
	2352616966608 -> 2352616966416
	2352532461104 [label="layer2.0.bn_proj.weight
 (64)" fillcolor=lightblue]
	2352532461104 -> 2352616966608
	2352616966608 [label=AccumulateGrad]
	2352616966176 -> 2352616966416
	2352532461184 [label="layer2.0.bn_proj.bias
 (64)" fillcolor=lightblue]
	2352532461184 -> 2352616966176
	2352616966176 [label=AccumulateGrad]
	2352616965984 -> 2352616965408
	2352532461584 [label="layer2.0.projection.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2352532461584 -> 2352616965984
	2352616965984 [label=AccumulateGrad]
	2352616965312 -> 2352616965168
	2352532461664 [label="layer2.1.block.bn1.weight
 (128)" fillcolor=lightblue]
	2352532461664 -> 2352616965312
	2352616965312 [label=AccumulateGrad]
	2352616965264 -> 2352616965168
	2352532461744 [label="layer2.1.block.bn1.bias
 (128)" fillcolor=lightblue]
	2352532461744 -> 2352616965264
	2352616965264 [label=AccumulateGrad]
	2352616964976 -> 2352616964832
	2352532462144 [label="layer2.1.block.conv_x_1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2352532462144 -> 2352616964976
	2352616964976 [label=AccumulateGrad]
	2352616964784 -> 2352616964688
	2352532462224 [label="layer2.1.block.bn2.weight
 (128)" fillcolor=lightblue]
	2352532462224 -> 2352616964784
	2352616964784 [label=AccumulateGrad]
	2352616964736 -> 2352616964688
	2352532462304 [label="layer2.1.block.bn2.bias
 (128)" fillcolor=lightblue]
	2352532462304 -> 2352616964736
	2352616964736 [label=AccumulateGrad]
	2352616964496 -> 2352616964400
	2352532462704 [label="layer2.1.block.conv_x_2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2352532462704 -> 2352616964496
	2352616964496 [label=AccumulateGrad]
	2352616964352 -> 2352538967200
	2352616964256 -> 2352538968016
	2352532462784 [label="layer2.2.block.bn1.weight
 (128)" fillcolor=lightblue]
	2352532462784 -> 2352616964256
	2352616964256 [label=AccumulateGrad]
	2352616964208 -> 2352538968016
	2352532462864 [label="layer2.2.block.bn1.bias
 (128)" fillcolor=lightblue]
	2352532462864 -> 2352616964208
	2352616964208 [label=AccumulateGrad]
	2352538967824 -> 2352538967680
	2352532463264 [label="layer2.2.block.conv_x_1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2352532463264 -> 2352538967824
	2352538967824 [label=AccumulateGrad]
	2352538967632 -> 2352538967536
	2352532463344 [label="layer2.2.block.bn2.weight
 (128)" fillcolor=lightblue]
	2352532463344 -> 2352538967632
	2352538967632 [label=AccumulateGrad]
	2352538967584 -> 2352538967536
	2352532463424 [label="layer2.2.block.bn2.bias
 (128)" fillcolor=lightblue]
	2352532463424 -> 2352538967584
	2352538967584 [label=AccumulateGrad]
	2352538967344 -> 2352538967248
	2352532529456 [label="layer2.2.block.conv_x_2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2352532529456 -> 2352538967344
	2352538967344 [label=AccumulateGrad]
	2352538967200 -> 2352538966144
	2352538967104 -> 2352538966960
	2352532529536 [label="layer2.3.block.bn1.weight
 (128)" fillcolor=lightblue]
	2352532529536 -> 2352538967104
	2352538967104 [label=AccumulateGrad]
	2352538967056 -> 2352538966960
	2352532529616 [label="layer2.3.block.bn1.bias
 (128)" fillcolor=lightblue]
	2352532529616 -> 2352538967056
	2352538967056 [label=AccumulateGrad]
	2352538966768 -> 2352538966624
	2352532530016 [label="layer2.3.block.conv_x_1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2352532530016 -> 2352538966768
	2352538966768 [label=AccumulateGrad]
	2352538966576 -> 2352538966480
	2352532530096 [label="layer2.3.block.bn2.weight
 (128)" fillcolor=lightblue]
	2352532530096 -> 2352538966576
	2352538966576 [label=AccumulateGrad]
	2352538966528 -> 2352538966480
	2352532530176 [label="layer2.3.block.bn2.bias
 (128)" fillcolor=lightblue]
	2352532530176 -> 2352538966528
	2352538966528 [label=AccumulateGrad]
	2352538966288 -> 2352538966192
	2352532530576 [label="layer2.3.block.conv_x_2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2352532530576 -> 2352538966288
	2352538966288 [label=AccumulateGrad]
	2352538966144 -> 2352538966000
	2352538965952 -> 2352538965856
	2352532530656 [label="layer3.0.block.bn1.weight
 (128)" fillcolor=lightblue]
	2352532530656 -> 2352538965952
	2352538965952 [label=AccumulateGrad]
	2352538965904 -> 2352538965856
	2352532530736 [label="layer3.0.block.bn1.bias
 (128)" fillcolor=lightblue]
	2352532530736 -> 2352538965904
	2352538965904 [label=AccumulateGrad]
	2352538965664 -> 2352538965520
	2352532531136 [label="layer3.0.block.conv_x_1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2352532531136 -> 2352538965664
	2352538965664 [label=AccumulateGrad]
	2352538965472 -> 2352538965376
	2352532531216 [label="layer3.0.block.bn2.weight
 (256)" fillcolor=lightblue]
	2352532531216 -> 2352538965472
	2352538965472 [label=AccumulateGrad]
	2352538965424 -> 2352538965376
	2352532531296 [label="layer3.0.block.bn2.bias
 (256)" fillcolor=lightblue]
	2352532531296 -> 2352538965424
	2352538965424 [label=AccumulateGrad]
	2352538965184 -> 2352538965088
	2352532531696 [label="layer3.0.block.conv_x_2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352532531696 -> 2352538965184
	2352538965184 [label=AccumulateGrad]
	2352538965040 -> 2352538951584
	2352538965040 [label=ConvolutionBackward0]
	2352538965568 -> 2352538965040
	2352538965568 [label=ReluBackward0]
	2352538966048 -> 2352538965568
	2352538966048 [label=NativeBatchNormBackward0]
	2352538966000 -> 2352538966048
	2352538966240 -> 2352538966048
	2352532531776 [label="layer3.0.bn_proj.weight
 (128)" fillcolor=lightblue]
	2352532531776 -> 2352538966240
	2352538966240 [label=AccumulateGrad]
	2352538965808 -> 2352538966048
	2352532531856 [label="layer3.0.bn_proj.bias
 (128)" fillcolor=lightblue]
	2352532531856 -> 2352538965808
	2352538965808 [label=AccumulateGrad]
	2352538965616 -> 2352538965040
	2352532532256 [label="layer3.0.projection.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2352532532256 -> 2352538965616
	2352538965616 [label=AccumulateGrad]
	2352538964944 -> 2352538964800
	2352532532336 [label="layer3.1.block.bn1.weight
 (256)" fillcolor=lightblue]
	2352532532336 -> 2352538964944
	2352538964944 [label=AccumulateGrad]
	2352538964896 -> 2352538964800
	2352532532416 [label="layer3.1.block.bn1.bias
 (256)" fillcolor=lightblue]
	2352532532416 -> 2352538964896
	2352538964896 [label=AccumulateGrad]
	2352538964608 -> 2352538964464
	2352532532816 [label="layer3.1.block.conv_x_1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352532532816 -> 2352538964608
	2352538964608 [label=AccumulateGrad]
	2352538964416 -> 2352538964320
	2352532532896 [label="layer3.1.block.bn2.weight
 (256)" fillcolor=lightblue]
	2352532532896 -> 2352538964416
	2352538964416 [label=AccumulateGrad]
	2352538964368 -> 2352538964320
	2352532532976 [label="layer3.1.block.bn2.bias
 (256)" fillcolor=lightblue]
	2352532532976 -> 2352538964368
	2352538964368 [label=AccumulateGrad]
	2352538964128 -> 2352538951632
	2352538714336 [label="layer3.1.block.conv_x_2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352538714336 -> 2352538964128
	2352538964128 [label=AccumulateGrad]
	2352538951584 -> 2352538950576
	2352538951536 -> 2352538951392
	2352538714416 [label="layer3.2.block.bn1.weight
 (256)" fillcolor=lightblue]
	2352538714416 -> 2352538951536
	2352538951536 [label=AccumulateGrad]
	2352538951488 -> 2352538951392
	2352538714496 [label="layer3.2.block.bn1.bias
 (256)" fillcolor=lightblue]
	2352538714496 -> 2352538951488
	2352538951488 [label=AccumulateGrad]
	2352538951200 -> 2352538951056
	2352538714896 [label="layer3.2.block.conv_x_1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352538714896 -> 2352538951200
	2352538951200 [label=AccumulateGrad]
	2352538951008 -> 2352538950912
	2352538714976 [label="layer3.2.block.bn2.weight
 (256)" fillcolor=lightblue]
	2352538714976 -> 2352538951008
	2352538951008 [label=AccumulateGrad]
	2352538950960 -> 2352538950912
	2352538715056 [label="layer3.2.block.bn2.bias
 (256)" fillcolor=lightblue]
	2352538715056 -> 2352538950960
	2352538950960 [label=AccumulateGrad]
	2352538950720 -> 2352538950624
	2352538715456 [label="layer3.2.block.conv_x_2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352538715456 -> 2352538950720
	2352538950720 [label=AccumulateGrad]
	2352538950576 -> 2352538949520
	2352538950480 -> 2352538950336
	2352538715536 [label="layer3.3.block.bn1.weight
 (256)" fillcolor=lightblue]
	2352538715536 -> 2352538950480
	2352538950480 [label=AccumulateGrad]
	2352538950432 -> 2352538950336
	2352538715616 [label="layer3.3.block.bn1.bias
 (256)" fillcolor=lightblue]
	2352538715616 -> 2352538950432
	2352538950432 [label=AccumulateGrad]
	2352538950144 -> 2352538950000
	2352538716016 [label="layer3.3.block.conv_x_1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352538716016 -> 2352538950144
	2352538950144 [label=AccumulateGrad]
	2352538949952 -> 2352538949856
	2352538716096 [label="layer3.3.block.bn2.weight
 (256)" fillcolor=lightblue]
	2352538716096 -> 2352538949952
	2352538949952 [label=AccumulateGrad]
	2352538949904 -> 2352538949856
	2352538716176 [label="layer3.3.block.bn2.bias
 (256)" fillcolor=lightblue]
	2352538716176 -> 2352538949904
	2352538949904 [label=AccumulateGrad]
	2352538949664 -> 2352538949568
	2352538716576 [label="layer3.3.block.conv_x_2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352538716576 -> 2352538949664
	2352538949664 [label=AccumulateGrad]
	2352538949520 -> 2352538948464
	2352538949424 -> 2352538949280
	2352538716656 [label="layer3.4.block.bn1.weight
 (256)" fillcolor=lightblue]
	2352538716656 -> 2352538949424
	2352538949424 [label=AccumulateGrad]
	2352538949376 -> 2352538949280
	2352538716736 [label="layer3.4.block.bn1.bias
 (256)" fillcolor=lightblue]
	2352538716736 -> 2352538949376
	2352538949376 [label=AccumulateGrad]
	2352538949088 -> 2352538948944
	2352538717136 [label="layer3.4.block.conv_x_1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352538717136 -> 2352538949088
	2352538949088 [label=AccumulateGrad]
	2352538948896 -> 2352538948800
	2352538717216 [label="layer3.4.block.bn2.weight
 (256)" fillcolor=lightblue]
	2352538717216 -> 2352538948896
	2352538948896 [label=AccumulateGrad]
	2352538948848 -> 2352538948800
	2352538717296 [label="layer3.4.block.bn2.bias
 (256)" fillcolor=lightblue]
	2352538717296 -> 2352538948848
	2352538948848 [label=AccumulateGrad]
	2352538948608 -> 2352538948512
	2352538717696 [label="layer3.4.block.conv_x_2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352538717696 -> 2352538948608
	2352538948608 [label=AccumulateGrad]
	2352538948464 -> 2352538939152
	2352538948368 -> 2352538948224
	2352538717776 [label="layer3.5.block.bn1.weight
 (256)" fillcolor=lightblue]
	2352538717776 -> 2352538948368
	2352538948368 [label=AccumulateGrad]
	2352538948320 -> 2352538948224
	2352538717856 [label="layer3.5.block.bn1.bias
 (256)" fillcolor=lightblue]
	2352538717856 -> 2352538948320
	2352538948320 [label=AccumulateGrad]
	2352538948032 -> 2352538947888
	2352538787984 [label="layer3.5.block.conv_x_1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352538787984 -> 2352538948032
	2352538948032 [label=AccumulateGrad]
	2352538947840 -> 2352538947744
	2352538788064 [label="layer3.5.block.bn2.weight
 (256)" fillcolor=lightblue]
	2352538788064 -> 2352538947840
	2352538947840 [label=AccumulateGrad]
	2352538947792 -> 2352538947744
	2352538788144 [label="layer3.5.block.bn2.bias
 (256)" fillcolor=lightblue]
	2352538788144 -> 2352538947792
	2352538947792 [label=AccumulateGrad]
	2352538939296 -> 2352538939200
	2352538788544 [label="layer3.5.block.conv_x_2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2352538788544 -> 2352538939296
	2352538939296 [label=AccumulateGrad]
	2352538939152 -> 2352538939008
	2352538938960 -> 2352538938864
	2352538788624 [label="layer4.0.block.bn1.weight
 (256)" fillcolor=lightblue]
	2352538788624 -> 2352538938960
	2352538938960 [label=AccumulateGrad]
	2352538938912 -> 2352538938864
	2352538788704 [label="layer4.0.block.bn1.bias
 (256)" fillcolor=lightblue]
	2352538788704 -> 2352538938912
	2352538938912 [label=AccumulateGrad]
	2352538938672 -> 2352538938528
	2352538789104 [label="layer4.0.block.conv_x_1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2352538789104 -> 2352538938672
	2352538938672 [label=AccumulateGrad]
	2352538938480 -> 2352538938384
	2352538789184 [label="layer4.0.block.bn2.weight
 (512)" fillcolor=lightblue]
	2352538789184 -> 2352538938480
	2352538938480 [label=AccumulateGrad]
	2352538938432 -> 2352538938384
	2352538789264 [label="layer4.0.block.bn2.bias
 (512)" fillcolor=lightblue]
	2352538789264 -> 2352538938432
	2352538938432 [label=AccumulateGrad]
	2352538938192 -> 2352538938096
	2352538789664 [label="layer4.0.block.conv_x_2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2352538789664 -> 2352538938192
	2352538938192 [label=AccumulateGrad]
	2352538938048 -> 2352538937088
	2352538938048 [label=ConvolutionBackward0]
	2352538938576 -> 2352538938048
	2352538938576 [label=ReluBackward0]
	2352538939056 -> 2352538938576
	2352538939056 [label=NativeBatchNormBackward0]
	2352538939008 -> 2352538939056
	2352538939248 -> 2352538939056
	2352538789744 [label="layer4.0.bn_proj.weight
 (256)" fillcolor=lightblue]
	2352538789744 -> 2352538939248
	2352538939248 [label=AccumulateGrad]
	2352538938816 -> 2352538939056
	2352538789824 [label="layer4.0.bn_proj.bias
 (256)" fillcolor=lightblue]
	2352538789824 -> 2352538938816
	2352538938816 [label=AccumulateGrad]
	2352538938624 -> 2352538938048
	2352538790224 [label="layer4.0.projection.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2352538790224 -> 2352538938624
	2352538938624 [label=AccumulateGrad]
	2352538937952 -> 2352538937856
	2352538790304 [label="layer4.1.block.bn1.weight
 (512)" fillcolor=lightblue]
	2352538790304 -> 2352538937952
	2352538937952 [label=AccumulateGrad]
	2352538937904 -> 2352538937856
	2352538790384 [label="layer4.1.block.bn1.bias
 (512)" fillcolor=lightblue]
	2352538790384 -> 2352538937904
	2352538937904 [label=AccumulateGrad]
	2352538937664 -> 2352538937520
	2352538790784 [label="layer4.1.block.conv_x_1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2352538790784 -> 2352538937664
	2352538937664 [label=AccumulateGrad]
	2352538937472 -> 2352538937424
	2352538790864 [label="layer4.1.block.bn2.weight
 (512)" fillcolor=lightblue]
	2352538790864 -> 2352538937472
	2352538937472 [label=AccumulateGrad]
	2352538937328 -> 2352538937424
	2352538790944 [label="layer4.1.block.bn2.bias
 (512)" fillcolor=lightblue]
	2352538790944 -> 2352538937328
	2352538937328 [label=AccumulateGrad]
	2352538937232 -> 2352538937136
	2352538791344 [label="layer4.1.block.conv_x_2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2352538791344 -> 2352538937232
	2352538937232 [label=AccumulateGrad]
	2352538937088 -> 2352538936128
	2352538936992 -> 2352538936896
	2352538791424 [label="layer4.2.block.bn1.weight
 (512)" fillcolor=lightblue]
	2352538791424 -> 2352538936992
	2352538936992 [label=AccumulateGrad]
	2352538936944 -> 2352538936896
	2352538791504 [label="layer4.2.block.bn1.bias
 (512)" fillcolor=lightblue]
	2352538791504 -> 2352538936944
	2352538936944 [label=AccumulateGrad]
	2352538936704 -> 2352538936560
	2352538865728 [label="layer4.2.block.conv_x_1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2352538865728 -> 2352538936704
	2352538936704 [label=AccumulateGrad]
	2352538936512 -> 2352538936464
	2352538865808 [label="layer4.2.block.bn2.weight
 (512)" fillcolor=lightblue]
	2352538865808 -> 2352538936512
	2352538936512 [label=AccumulateGrad]
	2352538936368 -> 2352538936464
	2352538865888 [label="layer4.2.block.bn2.bias
 (512)" fillcolor=lightblue]
	2352538865888 -> 2352538936368
	2352538936368 [label=AccumulateGrad]
	2352538936272 -> 2352538936176
	2352538866288 [label="layer4.2.block.conv_x_2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2352538866288 -> 2352538936272
	2352538936272 [label=AccumulateGrad]
	2352538936128 -> 2352538935984
	2352538935936 -> 2352538935888
	2352538866368 [label="post_bn.weight
 (512)" fillcolor=lightblue]
	2352538866368 -> 2352538935936
	2352538935936 [label=AccumulateGrad]
	2352538935504 -> 2352538935888
	2352538866448 [label="post_bn.bias
 (512)" fillcolor=lightblue]
	2352538866448 -> 2352538935504
	2352538935504 [label=AccumulateGrad]
	2352538935408 -> 2352532578112
	2352538935408 [label=TBackward0]
	2352538935744 -> 2352538935408
	2352538866768 [label="linear.weight
 (1000, 512)" fillcolor=lightblue]
	2352538866768 -> 2352538935744
	2352538935744 [label=AccumulateGrad]
	2352532578256 -> 2352532578208
	2352538866848 [label="linear.bias
 (1000)" fillcolor=lightblue]
	2352538866848 -> 2352532578256
	2352532578256 [label=AccumulateGrad]
	2352532578208 -> 2352538901456
}
